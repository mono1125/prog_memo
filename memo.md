# 時系列データの前処理方法
## 平滑化
    -   データを均すことでノイズを低減する
    -   平滑化しすぎると特徴量が失われる
## 微分
    -   データの傾きを計算することで
        -   ベースラインの補正
        -   新しい情報を抽出する
        -   時間変化を得る
    -   一次微分、二次微分、三次微分...
    -   微分するとノイズが大きくなるので注意
## 単純移動平均
    現在時刻の値を含めて過去n点でのプロセス変数の平均値を平滑化後の値にする
    -   時刻ごとに計算する
    -   nを窓枠の数という
    -   初期時刻付近についてはn点とれないこともある
## 線形加重移動平均
    現在時刻の値を含めて過去n点でのプロセス変数の値について現在時刻から離れるにつれて **線形に重みが小さくなる加重平均**の値を平滑化後の値にする。
    -   (2n+1)を窓枠の数と呼ぶ
    ある時刻$t$におけるプロセス変数の値を$x_t$として平滑化後の値を$x_{S, t}$とすると
    $x_{S,t} = \frac{\sum^{n}_{j=1} \{(n-j+1)x_{t-j+1}\}{\sum^{n}_{j=1}(n-j+1)}$
## 指数加重移動平均
    現在時刻の値を含めて過去n点でのプロセス変数の値について現在時刻から離れるにつれて**指数関数的に重みが小さくなる加重平均**の値を平滑化後の値にする
    -   波長からある程度離れると重みはほぼ0になるため窓枠をある程度大きくしておけば細かい数字は気にしなくて良い

    ある時刻$t$におけるプロセス変数の値を$x_t$として平滑化後の値を$x_{S, t}$とすると
    $x_{S, t} = \alpha\{x_{t} + (1-\alpha)x_{t-1}+{(1-\alpha)^2}x_{t-2}+\dots\}

    $\alpha$を平滑化係数と呼ぶ
## 微分
    -   隣の波長・時刻における値との差分を取ることで一次微分
    -   一次微分の値について隣の波長・時刻における値との差分をとることで二次微分

## Savitzky-Golay(SG)法
    -   データの平滑化と微分とを同時に行う方法
        -   窓枠のデータを多項式で近似して多項式の計算値を平滑化後の値とする
        -   多項式の微分係数を微分後の値とする -> 時刻ごとに計算
    -   時系列データに用いられる例はあまりないが効果はある(H.kaneko 50,422-429,2017)
    -   多項式の次数と窓枠の数を事前に決めなければならない
## 手法・ハイパパラメタ・微分次数はどう決めるか
    手法とパラメタ値の候補
    -   単純移動平均: 窓枠の数
    -   線形加重移動平均: 窓枠の数
    -   指数加重移動平均: 平滑化係数
    -   SG法: 多項式の次数、窓枠の数
    微分次数
    これらをどう決めるか
    -   モデルの検証により選択
        -   各手法・ハイパパラメタ・各微分係数の値で回帰分析・クラス分類のモデル検証を行って**最も検証結果の良い組み合わせを選択**する。
        -   メリット: モデルの検証の仕方次第で**推定性能の高いモデル**を構築できる手法・ハイパパラメタ値・微分係数を選択できる。
        -   デメリット: 教師ありデータが必要かつ、試行錯誤を要する
    - ノイズの正規分布性により選択する
        -   平滑化前後の値を引くことで平滑化によって**均された** ノイズの値を計算できる。
        -   ノイズは正規分布であると仮定すると平滑化によって減少したノイズの分布も正規分布に従う必要がある。
        -   コルモゴロフ-スミルノフ検定などの正規分布性の検定によりノイズが正規分布に従う手法・ハイパパラメタの組み合わせを選択
        -   選択された手法・ハイパパラメタの組の中で標準偏差が最も大きい(=ノイズが最も減少した)組を選択
        -   メリット: 教師データ不要・モデリング不要
        -   デメリット: 微分次数は選択できない・選択の際にモデルの推定性能は考慮されていない。

# 時系列データ解析の前処理(参考: https://stats.biopapyrus.jp/time-series/scale.html)
## 変数変換
### 対数変換
    値が著しく大きい時系列データの場合、データの変動も大きくなりがちである。このような場合データに対して対数変換することでデータが持つ時系列的な傾向を保ったまま値を小さく変換することができる。
### ロジット変換
    値が0から1までの値をとる確率あるいは割合データの場合、ロジット変換を施すと確率・割合データはマイナス無限大からプラス無限大の値に変換される。
    変換後のデータをつかことで様々な時系列モデルに当てはめて解析できるようになる
### 差分(階差)
    ある時点tのときの値とその直前の時点t-1のときの値の差分を計算してそれを新しいデータとする。上昇あるいは下降のトレンドを持つ時系列データのとき差分を計算することでトレンドを取り除くことができる。
### 対数差分
    時系列データが変化率や成長率などである場合、対数差分を計算して解析することがある。
    時点t-1と時点tの間隔が短く、両時点で観測した値が非常に近い値を取る場合、対数差分が0に限りなく近い値を取る。
    そのため、対数差分を一時的に$\delta log(y_t)$のテイラー展開の1次近似とする。
### 比
    変化率や成長率などの時系列データを解析する場合、時点tと時点t-sの比を計算して解析することもある。


# 異常検知手法
## 外れ値検出(検出単位: データ点)
    外れ値検出は普段は起こり得ないようなデータ点を検知する手法。窓を設定して区間を限定することで時系列データの外れ値検出に対してk近傍法が適用できる。
### k近傍法を用いた外れ値検知の手順
    1.直前の時系列データからある一定の窓幅の部分時系列を取り出す
    1.新たに得られたデータ点と部分時系列のそれぞれのデータ点までの距離をすべて計算する。
    1.前項で計算した距離のうち最も短いものをk個選び、その平均を新たに得られたデータ点の異常度とする。
    1.異常度がある閾値以上であれば外れ値として検知する
    データが更新されるたびに窓をずらして部分時系列系列を取り出して上記の処理を行えばリアルタイムに外れ値検出ができる。
    * 実際の問題に応用する場合には精度を向上させるために異常度の閾値と窓枠の値をチューニングする必要がある

## 異常部位検出(検出単位: 部分時系列)
    異常部位検出は異常が起きている部分時系列を検出する手法。部分位置検出にもk近傍法を用いることができる。外れ値検出との違いはデータ点ではなく部分時系列が異常かどうかを評価するところにある。
### k近傍法を用いた異常部位検出の手順
    1.時系列データをtrainデータとtestデータに分ける
    1.trainデータとtestデータからそれぞれ同じ窓幅の部分時系列を複数個取り出す。
    1.訓練データの部分時系列と検証データの部分時系列の類似度または非類似度をすべて計算する。
    1.前項で計算した{類似度 | 非類似度}が最も{高い | 低い}ものをk個選びその平均を検証データの部分時系列の異常度とする
    1.異常度がある閾値以上であれば異常部位として検出する
    * データ間の非類似度としてユークリッド距離が多く使われるがLpノルムや2つの時系列データの類似度を計算するDynamic Time Wrapingなど任意の{類似度 | 非類似度}を用いることができる。
## 変化点検知(検出単位: 変化が起きた時点)
    時系列データのパターンが急激に変化する箇所を検知するための手法。
### ホテリング理論を応用した変化点検知
    ホテリング理論を応用した変化点検出には予測モデルが必要。信頼性のある予測モデルがあれば将来のデータをある程度の範囲内で予測することができるが、普段予測できるということは予測が全く当たらなかった場合、その時点でなにか大きな変化があったと考えられる。
    このアイデアに基づいて予測値と実測値のズレを異常度と定義して変化点を検知する。具体的にはズレがマイナスになる場合も想定して**予測値と実測値の差の2乗**を異常度と定義する。

#### 予測に使用するモデルを検討する。
    時系列予測で最も幅広く使用されているモデルはARモデル(自己回帰モデル)。ARモデルとは直前のデータ点をもとに将来のデータ点をもとに将来のデータ点を予測するモデル。直前の何時点までを予測に用いるかを表すパラメタは次数と呼ばれる。

    次数3のARモデルを検討する。将来のデータ$x(t)$を過去のデータ$x(t-1)$,$x(t-2)$,$x(t-3)$とすると、次のようになる
    $\hat{x}(t) = \beta_{1}x(t-1) + \beta_{2}x(t-2) + \beta_{3}x(t-3)$

    将来のデータ予測値$x(t)$は過去の3つのデータ点と係数($\beta_{1}, \beta_{2}, \beta_{3}$)の積和で表す。通常、予測値と実測値には差がありこれを残差$\epsilon(t)$と呼ぶ

    $x(t) - \hat{x}(t) = \epsilon(t)$

    残差が小さいほど精度の高いモデルで逆に残差が大きいほど精度の低いモデル。
    実際には次数はモデルの予測精度に大きく影響を与えるため、慎重に定める必要がある。

### ARモデルを用いた変化点検知の手順
    1.時系列データをtrainデータとtestデータに分ける
    1.訓練データからARモデルを推定する
    1.前項で求めたARモデルを使用して検証データを予測する
    1.(予測値 - 実測値)^2を各時点での異常度とする
    1.異常度がある閾値以上であればその時点を変化点とする
    データが更新されるたびに異常度を計算することでリアルタイムに変化点検知ができる。またARモデルでの予測が難しい場合はARMAモデルや状態空間モデルなどのより複雑なモデルを用いて検証データの予測を行うことで任意の時系列データに対して変化点検知が可能になる。

# フィルタ
    基本的な考え方は要らない情報を抽出・排除してほしい情報のみを通過させること。
## フィルタ設計
    基本は以下の3ステップで設計
    1.入力値からどんな値を検出するか？
    1.どんなアルゴリズムで検出するか？
    1.検出した値をどう排除するか？

# Hampelフィルタ
    データを窓単位で分割して3σ法で外れ値(スパイク)検出をするのがHampelフィルタの特徴
    Hampelフィルタ設計は次の通り
    1.入力ベクトルに含まれる外れ値(スパイク)が検出対象
    1.窓ごとに3σ法を適用して外れ値(スパイク)を検出
    1.検出した値を窓ごとの中央値に置き換える
## Hampelフィルタ処理のアルゴリズム
    1.窓サイズ(フィルタを適用するプロット数)を設定
    1.窓内のプロット値から中央値を算出
    1.中央絶対偏差を用いて中央値に対する標準偏差を推定
    1.プロット値が標準偏差のn倍より大きい場合は中央値に置き換える(通常はn=3を使用)
